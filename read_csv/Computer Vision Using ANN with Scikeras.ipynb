{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15c922a",
   "metadata": {
    "id": "f15c922a"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af900e97",
   "metadata": {
    "id": "af900e97"
   },
   "outputs": [],
   "source": [
    "dfAll = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "df = dfAll[((dfAll.label == 0) | (dfAll.label == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d716eff",
   "metadata": {
    "id": "3d716eff",
    "outputId": "cd4bd8ea-fb28-4afa-9455-b87e8cf95d87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 785)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a91626a7-babe-4ba9-8689-85c619e59b46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1728015728960,
     "user": {
      "displayName": "Keshav Pal Singh",
      "userId": "06251047689440895898"
     },
     "user_tz": -330
    },
    "id": "a91626a7-babe-4ba9-8689-85c619e59b46",
    "outputId": "2fe707f5-a02a-41fb-d11c-6be59d661c2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>177</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "3       0       0       0       0       1       2       0       0       0   \n",
       "10      0       0       0       0       0       1       0       0       0   \n",
       "13      0       0       0       0       0       0       0       0       0   \n",
       "24      0       0       0       0       0       0       0       0       0   \n",
       "29      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "3        0  ...         3         0         0         0         0         1   \n",
       "10       0  ...       164       177       163         0         0         1   \n",
       "13       0  ...         0         0         0         0         0         0   \n",
       "24      40  ...       125        93        87        49         0         0   \n",
       "29       0  ...         0         1         0         0         0         0   \n",
       "\n",
       "    pixel781  pixel782  pixel783  pixel784  \n",
       "3          0         0         0         0  \n",
       "10         0         0         0         0  \n",
       "13         1         0         0         0  \n",
       "24         0         0         0         0  \n",
       "29         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f9d71c-5f64-47fe-aee4-00b62cdc3d9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1728015734123,
     "user": {
      "displayName": "Keshav Pal Singh",
      "userId": "06251047689440895898"
     },
     "user_tz": -330
    },
    "id": "19f9d71c-5f64-47fe-aee4-00b62cdc3d9a",
    "outputId": "086f42e2-584d-41ec-80f9-49ee80f02382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3        0\n",
       "10       0\n",
       "13       0\n",
       "24       0\n",
       "29       1\n",
       "        ..\n",
       "59967    0\n",
       "59969    1\n",
       "59980    0\n",
       "59990    0\n",
       "59996    1\n",
       "Name: label, Length: 12000, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dd86a2f",
   "metadata": {
    "id": "5dd86a2f"
   },
   "outputs": [],
   "source": [
    "# We will split our data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"label\"], axis=1)\n",
    "Y = df.label\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce26667",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1728015744687,
     "user": {
      "displayName": "Keshav Pal Singh",
      "userId": "06251047689440895898"
     },
     "user_tz": -330
    },
    "id": "9ce26667",
    "outputId": "bb8baa75-7ce0-4294-c54a-d0009862c223"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example Images\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_train.head().values[i].reshape(28,28), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550938a6",
   "metadata": {
    "id": "550938a6"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.values.T\n",
    "y_train = y_train.values.reshape(8400,1).T\n",
    "x_test = x_test.values.T\n",
    "y_test = y_test.values.reshape(3600,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2XTFVO-Z2GJz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194519,
     "status": "ok",
     "timestamp": 1728017300267,
     "user": {
      "displayName": "Keshav Pal Singh",
      "userId": "06251047689440895898"
     },
     "user_tz": -330
    },
    "id": "2XTFVO-Z2GJz",
    "outputId": "5d11a804-de94-4762-d5bb-bdaf8347fab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\pushp\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from scikeras) (3.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from scikeras) (1.5.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.24.4)\n",
      "Requirement already satisfied: rich in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (23.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pushp\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.8705 - loss: 0.4251\n",
      "Epoch 2/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9783 - loss: 0.2956\n",
      "Epoch 3/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9798 - loss: 0.2027\n",
      "Epoch 4/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9853 - loss: 0.1238\n",
      "Epoch 5/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9863 - loss: 0.0908\n",
      "Epoch 6/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9890 - loss: 0.0653\n",
      "Epoch 7/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9871 - loss: 0.0551\n",
      "Epoch 8/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9885 - loss: 0.0520\n",
      "Epoch 9/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9909 - loss: 0.0453\n",
      "Epoch 10/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9898 - loss: 0.0395\n",
      "Epoch 11/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0294\n",
      "Epoch 12/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9930 - loss: 0.0312\n",
      "Epoch 13/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9945 - loss: 0.0244\n",
      "Epoch 14/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9918 - loss: 0.0298\n",
      "Epoch 15/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9943 - loss: 0.0226\n",
      "Epoch 16/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.9934 - loss: 0.0249\n",
      "Epoch 17/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9925 - loss: 0.0244\n",
      "Epoch 18/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9928 - loss: 0.0243\n",
      "Epoch 19/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9947 - loss: 0.0201\n",
      "Epoch 20/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9933 - loss: 0.0312\n",
      "Epoch 21/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9927 - loss: 0.0248\n",
      "Epoch 22/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9960 - loss: 0.0196\n",
      "Epoch 23/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9945 - loss: 0.0211\n",
      "Epoch 24/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.9941 - loss: 0.0220\n",
      "Epoch 25/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9970 - loss: 0.0191\n",
      "Epoch 26/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9965 - loss: 0.0145\n",
      "Epoch 27/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9940 - loss: 0.0235\n",
      "Epoch 28/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.9980 - loss: 0.0116\n",
      "Epoch 29/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9969 - loss: 0.0160\n",
      "Epoch 30/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0158\n",
      "Epoch 31/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9945 - loss: 0.0281\n",
      "Epoch 32/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9982 - loss: 0.0125\n",
      "Epoch 33/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9971 - loss: 0.0158\n",
      "Epoch 34/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9951 - loss: 0.0202\n",
      "Epoch 35/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0162\n",
      "Epoch 36/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0156\n",
      "Epoch 37/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9971 - loss: 0.0156\n",
      "Epoch 38/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0087\n",
      "Epoch 39/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9979 - loss: 0.0139\n",
      "Epoch 40/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9979 - loss: 0.0131\n",
      "Epoch 41/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9884 - loss: 0.0496\n",
      "Epoch 42/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9958 - loss: 0.0166\n",
      "Epoch 43/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9944 - loss: 0.0226\n",
      "Epoch 44/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0097\n",
      "Epoch 45/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9991 - loss: 0.0075\n",
      "Epoch 46/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9977 - loss: 0.0109\n",
      "Epoch 47/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9988 - loss: 0.0076\n",
      "Epoch 48/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9965 - loss: 0.0159\n",
      "Epoch 49/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9976 - loss: 0.0155\n",
      "Epoch 50/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9975 - loss: 0.0150\n",
      "Epoch 51/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9974 - loss: 0.0150\n",
      "Epoch 52/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0084\n",
      "Epoch 53/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9992 - loss: 0.0065\n",
      "Epoch 54/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0100\n",
      "Epoch 55/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9989 - loss: 0.0081\n",
      "Epoch 56/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0121\n",
      "Epoch 57/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9980 - loss: 0.0132\n",
      "Epoch 58/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0085\n",
      "Epoch 59/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0096\n",
      "Epoch 60/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9987 - loss: 0.0090\n",
      "Epoch 61/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9981 - loss: 0.0126\n",
      "Epoch 62/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9981 - loss: 0.0125\n",
      "Epoch 63/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0112\n",
      "Epoch 64/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9986 - loss: 0.0095\n",
      "Epoch 65/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9986 - loss: 0.0096\n",
      "Epoch 66/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0094\n",
      "Epoch 67/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0087\n",
      "Epoch 68/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0114\n",
      "Epoch 69/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9988 - loss: 0.0086\n",
      "Epoch 70/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0123\n",
      "Epoch 71/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9991 - loss: 0.0069\n",
      "Epoch 72/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9989 - loss: 0.0080\n",
      "Epoch 73/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9988 - loss: 0.0086\n",
      "Epoch 74/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0157\n",
      "Epoch 75/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0087\n",
      "Epoch 76/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0192\n",
      "Epoch 77/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0108\n",
      "Epoch 78/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0087\n",
      "Epoch 79/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9984 - loss: 0.0106\n",
      "Epoch 80/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0136\n",
      "Epoch 81/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0081\n",
      "Epoch 82/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.9983 - loss: 0.0112\n",
      "Epoch 83/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0099\n",
      "Epoch 84/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9990 - loss: 0.0070\n",
      "Epoch 85/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0061\n",
      "Epoch 86/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0074\n",
      "Epoch 87/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9990 - loss: 0.0073\n",
      "Epoch 88/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9986 - loss: 0.0096\n",
      "Epoch 89/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0115\n",
      "Epoch 90/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0129\n",
      "Epoch 91/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9988 - loss: 0.0084\n",
      "Epoch 92/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0096\n",
      "Epoch 93/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9989 - loss: 0.0081\n",
      "Epoch 94/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9988 - loss: 0.0087\n",
      "Epoch 95/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0093\n",
      "Epoch 96/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9987 - loss: 0.0093\n",
      "Epoch 97/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9931 - loss: 0.0430\n",
      "Epoch 98/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9894 - loss: 0.0402\n",
      "Epoch 99/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0153\n",
      "Epoch 100/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0113\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7939 - loss: 0.3391\n",
      "Epoch 2/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9823 - loss: 0.0472\n",
      "Epoch 3/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9835 - loss: 0.0424\n",
      "Epoch 4/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9871 - loss: 0.0355\n",
      "Epoch 5/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0348\n",
      "Epoch 6/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0243\n",
      "Epoch 7/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0278\n",
      "Epoch 8/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9913 - loss: 0.0270\n",
      "Epoch 9/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0257\n",
      "Epoch 10/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9927 - loss: 0.0226\n",
      "Epoch 11/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9900 - loss: 0.0341\n",
      "Epoch 12/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9947 - loss: 0.0181\n",
      "Epoch 13/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0196\n",
      "Epoch 14/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9952 - loss: 0.0152\n",
      "Epoch 15/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9915 - loss: 0.0214\n",
      "Epoch 16/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9958 - loss: 0.0120\n",
      "Epoch 17/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9952 - loss: 0.0152\n",
      "Epoch 18/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9946 - loss: 0.0170\n",
      "Epoch 19/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9959 - loss: 0.0133\n",
      "Epoch 20/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9958 - loss: 0.0142\n",
      "Epoch 21/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9959 - loss: 0.0117\n",
      "Epoch 22/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9955 - loss: 0.0127\n",
      "Epoch 23/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0075\n",
      "Epoch 24/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9940 - loss: 0.0126\n",
      "Epoch 25/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9953 - loss: 0.0114\n",
      "Epoch 26/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9985 - loss: 0.0067\n",
      "Epoch 27/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9958 - loss: 0.0108\n",
      "Epoch 28/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9980 - loss: 0.0063\n",
      "Epoch 29/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9895 - loss: 0.0274\n",
      "Epoch 30/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9943 - loss: 0.0148\n",
      "Epoch 31/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0095\n",
      "Epoch 32/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0076\n",
      "Epoch 33/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9984 - loss: 0.0067\n",
      "Epoch 34/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9951 - loss: 0.0132\n",
      "Epoch 35/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9968 - loss: 0.0112\n",
      "Epoch 36/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9977 - loss: 0.0064\n",
      "Epoch 37/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9979 - loss: 0.0059\n",
      "Epoch 38/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 39/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0058\n",
      "Epoch 40/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9961 - loss: 0.0106\n",
      "Epoch 41/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9925 - loss: 0.0241\n",
      "Epoch 42/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9984 - loss: 0.0049\n",
      "Epoch 43/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9981 - loss: 0.0050\n",
      "Epoch 44/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9985 - loss: 0.0048\n",
      "Epoch 45/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0048\n",
      "Epoch 46/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9956 - loss: 0.0103\n",
      "Epoch 47/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9970 - loss: 0.0149\n",
      "Epoch 48/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9983 - loss: 0.0045\n",
      "Epoch 49/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9981 - loss: 0.0061\n",
      "Epoch 50/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9990 - loss: 0.0051\n",
      "Epoch 51/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9986 - loss: 0.0035\n",
      "Epoch 52/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9975 - loss: 0.0053\n",
      "Epoch 53/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0039\n",
      "Epoch 54/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.9987 - loss: 0.0033\n",
      "Epoch 55/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9980 - loss: 0.0053\n",
      "Epoch 56/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9976 - loss: 0.0052\n",
      "Epoch 57/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9982 - loss: 0.0030\n",
      "Epoch 58/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9990 - loss: 0.0032\n",
      "Epoch 59/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9992 - loss: 0.0051\n",
      "Epoch 60/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0040\n",
      "Epoch 61/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9986 - loss: 0.0032\n",
      "Epoch 62/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9975 - loss: 0.0059\n",
      "Epoch 63/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9993 - loss: 0.0035\n",
      "Epoch 64/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0044\n",
      "Epoch 65/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9973 - loss: 0.0075\n",
      "Epoch 66/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9995 - loss: 0.0019\n",
      "Epoch 67/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9958 - loss: 0.0086\n",
      "Epoch 68/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0082\n",
      "Epoch 69/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0023\n",
      "Epoch 70/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9994 - loss: 0.0015  \n",
      "Epoch 71/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 72/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9973 - loss: 0.0072\n",
      "Epoch 73/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9986 - loss: 0.0046\n",
      "Epoch 74/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9963 - loss: 0.0134\n",
      "Epoch 75/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0032\n",
      "Epoch 76/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9977 - loss: 0.0047\n",
      "Epoch 77/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9948 - loss: 0.0087\n",
      "Epoch 78/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0032\n",
      "Epoch 79/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9967 - loss: 0.0070\n",
      "Epoch 80/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9989 - loss: 0.0021\n",
      "Epoch 81/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0041  \n",
      "Epoch 82/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9982 - loss: 0.0053\n",
      "Epoch 83/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0036\n",
      "Epoch 84/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0026\n",
      "Epoch 85/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0025\n",
      "Epoch 86/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0012\n",
      "Epoch 87/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0020\n",
      "Epoch 88/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0152\n",
      "Epoch 89/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0021\n",
      "Epoch 90/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0050\n",
      "Epoch 91/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9985 - loss: 0.0036\n",
      "Epoch 92/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0061\n",
      "Epoch 93/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0028  \n",
      "Epoch 94/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0021\n",
      "Epoch 95/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0020\n",
      "Epoch 96/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0029\n",
      "Epoch 97/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0012  \n",
      "Epoch 98/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0023\n",
      "Epoch 99/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0012\n",
      "Epoch 100/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9993 - loss: 0.0013  \n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\pushp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2585\n",
      "Epoch 2/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9841 - loss: 0.0460\n",
      "Epoch 3/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9857 - loss: 0.0372\n",
      "Epoch 4/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9846 - loss: 0.0393\n",
      "Epoch 5/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9897 - loss: 0.0252\n",
      "Epoch 6/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9883 - loss: 0.0338\n",
      "Epoch 7/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9895 - loss: 0.0285\n",
      "Epoch 8/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9922 - loss: 0.0213\n",
      "Epoch 9/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9924 - loss: 0.0187\n",
      "Epoch 10/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9928 - loss: 0.0178\n",
      "Epoch 11/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9951 - loss: 0.0157\n",
      "Epoch 12/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9925 - loss: 0.0173\n",
      "Epoch 13/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9919 - loss: 0.0237\n",
      "Epoch 14/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.9926 - loss: 0.0144\n",
      "Epoch 15/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0227\n",
      "Epoch 16/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0132  \n",
      "Epoch 17/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0120\n",
      "Epoch 18/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.9925 - loss: 0.0246\n",
      "Epoch 19/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9922 - loss: 0.0221\n",
      "Epoch 20/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0097  \n",
      "Epoch 21/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9954 - loss: 0.0109\n",
      "Epoch 22/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9964 - loss: 0.0081\n",
      "Epoch 23/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0062\n",
      "Epoch 24/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0038\n",
      "Epoch 25/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0124\n",
      "Epoch 26/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0043\n",
      "Epoch 27/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9977 - loss: 0.0076\n",
      "Epoch 28/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9943 - loss: 0.0212\n",
      "Epoch 29/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0109\n",
      "Epoch 30/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9978 - loss: 0.0064\n",
      "Epoch 31/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9990 - loss: 0.0021\n",
      "Epoch 32/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 33/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0076  \n",
      "Epoch 34/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9978 - loss: 0.0095\n",
      "Epoch 35/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9992 - loss: 0.0015\n",
      "Epoch 36/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0049\n",
      "Epoch 37/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 38/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9968 - loss: 0.0116\n",
      "Epoch 39/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9995 - loss: 0.0017  \n",
      "Epoch 40/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0098\n",
      "Epoch 41/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0129\n",
      "Epoch 42/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0072\n",
      "Epoch 43/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0090\n",
      "Epoch 44/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 45/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0202\n",
      "Epoch 46/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0036\n",
      "Epoch 47/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 48/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9985 - loss: 0.0038\n",
      "Epoch 49/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 50/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 51/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 52/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0023  \n",
      "Epoch 53/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0036\n",
      "Epoch 54/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0064\n",
      "Epoch 55/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0026\n",
      "Epoch 56/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0015\n",
      "Epoch 57/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0011  \n",
      "Epoch 58/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9993 - loss: 0.0011\n",
      "Epoch 59/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0010    \n",
      "Epoch 60/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 8.9552e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0151\n",
      "Epoch 62/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0042\n",
      "Epoch 63/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0011    \n",
      "Epoch 64/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9940 - loss: 0.0153\n",
      "Epoch 65/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9991 - loss: 0.0021\n",
      "Epoch 66/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9995 - loss: 0.0012\n",
      "Epoch 67/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0015\n",
      "Epoch 68/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9998 - loss: 7.7648e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9947 - loss: 0.0280\n",
      "Epoch 70/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0030\n",
      "Epoch 71/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9997 - loss: 8.2632e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9996 - loss: 0.0014\n",
      "Epoch 73/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9850 - loss: 0.0408\n",
      "Epoch 74/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 75/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0021\n",
      "Epoch 76/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0011\n",
      "Epoch 77/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0018\n",
      "Epoch 78/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9998 - loss: 7.9081e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 6.0574e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 6.6041e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0119\n",
      "Epoch 82/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0066\n",
      "Epoch 83/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 7.9855e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 85/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0012\n",
      "Epoch 86/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0011    \n",
      "Epoch 87/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 88/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 7.0740e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 3.7600e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9997 - loss: 7.6898e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9985 - loss: 0.0053\n",
      "Epoch 92/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0074\n",
      "Epoch 93/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0071\n",
      "Epoch 94/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 8.4748e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0012\n",
      "Epoch 96/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9998 - loss: 5.4390e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 6.5346e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0336\n",
      "Epoch 99/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 8.6298e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0029\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy Mean is 99.05%\n",
      "Accuracy Variance is 0.0008908708063747388\n"
     ]
    }
   ],
   "source": [
    "# Install the SciKeras package\n",
    "!pip install scikeras\n",
    "\n",
    "# Import the KerasClassifier from the correct module\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def buildClassifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=8, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=x_train.shape[0])) # Hidden Layer 1 with 8 nodes\n",
    "    classifier.add(Dense(units=6, kernel_initializer=\"uniform\", activation=\"relu\"))  # Hidden Layer 2 with 6 nodes\n",
    "    classifier.add(Dense(units=1, kernel_initializer=\"uniform\", activation=\"sigmoid\")) # Output Layer\n",
    "    classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "\n",
    "classifier = KerasClassifier(build_fn=buildClassifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train.T, y = y_train.T, cv=3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "\n",
    "print(\"Accuracy Mean is {:.2f}%\".format(mean*100))\n",
    "print(\"Accuracy Variance is {}\".format(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f7309-ba1c-464b-b31f-21e1f2e67725",
   "metadata": {
    "id": "fc5f7309-ba1c-464b-b31f-21e1f2e67725"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "13XNY9O3DbMRfY5Ez-Eu55BzqWr7w6_lA",
     "timestamp": 1728017837023
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
